# 1 ML策略

当我们面对一个深度神经网络模型时，我们通常希望从多个方面对其进行优化。一些常见的优化方法包括：

- 收集更多的数据
- 收集更多样的训练集
- 使用梯度下降算法或Adam优化算法来训练更长时间
- 尝试更大的网络
- 尝试更小的网络
- 添加dropout层
- 添加L2正则化
- 优化网络架构，如选择合适的激活函数和隐藏单元数量等。

然而，仅仅盲目选择和尝试这些方法可能会费时且效果甚微。因此，旨在快速、高效地找到最优机器学习模型的策略至关重要。

# 2 正交化方法

正交化是一种通用的调参策略，可以帮助我们更有效地调试和优化深度学习模型。

正交化方法的核心思想是每次只调整一个参数，保持其他参数不变，从而使模型在某一方面的性能发生改变。

可以将正交化方法类比为旧式电视机的旋钮。电视机的每个旋钮对应一个功能，调整一个旋钮只会影响对应功能的表现，而不会影响其他功能。也就是说，这些旋钮彼此之间是互不影响的，即正交的。通过这种方法，我们可以快速有效地调试和优化机器学习模型。

在监督式学习模型中，我们可以将优化分为四个独立的“功能”：

1. 在损失函数上更好地拟合训练集
2. 在损失函数上更好地拟合验证集
3. 在损失函数上更好地拟合测试集
4. 在实际应用中表现良好

为了实现这四个功能，我们可以采用不同的调节方法。

其中，第一条优化训练集可以通过使用更复杂NN，使用Adam等优化算法来实现；第二条优化验证集可以通过正则化，采用更多训练样本来实现；第三条优化测试集可以通过使用更多的验证集样本来实现；第四条提升实际应用模型可以通过更换验证集，使用新的cost function来实现。

然而，需要注意的是，在模型功能调试中不推荐使用早停法（early stopping），因为它会同时影响训练集和验证集的性能，不具有独立性、正交性，从而破坏了正交性的原则。

# 3 单值评估指标

在建立和优化机器学习模型时，使用单个指标来评估模型的性能非常重要。单值评估指标，把多个性能指标综合在一起，用于比较不同超参数对应的模型的优劣，从而选择最优模型。

举个例子，我们有模型A和模型B，它们的准确率和召回率如下：

- 模型A：准确率=0.8，召回率=0.6
- 模型B：准确率=0.7，召回率=0.8

如果只看准确率，模型B似乎更好；如果只看召回率，模型A似乎更好。为了综合考虑准确率(Precision)和召回率(Recall)，并进行比较，我们可以使用F1 Score作为单值评价指标。

F1 Score综合了准确率和召回率的大小，计算公式如下：
$$F1=\frac{2\cdot P\cdot R}{P+R}$$
通过计算，模型A的F1 Score为0.67，模型B的F1 Score为0.74。根据F1 Score，我们可以确定模型B比模型A更好。

除了F1 Score之外，还可以使用平均值作为单值评估指标，来评估模型的性能。例如，对于多个模型A, B, C, D, E, F，我们可以计算其在不同国家样本上的错误率，并选择平均错误率最小的模型作为最优模型。
![](assets/1机器学习策略(1).png)

# 4 优化指标和满意指标

有时候，要将所有的性能指标综合在一起构成单值评价指标会比较困难。为了解决这个问题，我们可以将某些性能作为优化指标（Optimizing metic），寻求最优化值；而将某些性能作为满意指标（Satisficing metic），只需要满足阈值即可。

以猫类识别为例，假设有A、B、C三个模型，它们的准确率（Accuracy）和运行时间（Running time）如下表所示：

模型 | 准确率 | 运行时间
----|------|----------
A   | 90%  | 60ms
B   | 92%  | 90ms
C   | 95%  | 1500ms

准确率和运行时间不太适合综合成单值评价指标。因此，可以将准确率作为优化指标，将运行时间作为满意指标。也就是说，在运行时间满足阈值的情况下，选择准确率最高的模型。

例如，如果设定运行时间必须在100ms以内，那么显然模型C不满足阈值条件，可以先剔除。然后比较模型A和模型B，发现模型B的准确率更高，性能更好。

总结来说，优化指标是需要优化的，越优越好；而满意指标只要满足设定的阈值就可以。

# 5 训练/验证/测试分布

Train/dev/test大小的设置对于机器学习模型训练非常重要，合理的设置可以大大提高模型训练效率和质量。

原则上，应该尽量保证dev集合和test集合来源于同一分布，并且都能够反映出实际样本的情况。如果dev集合和test集合不来自同一分布，那么从dev集合上选择的“最佳”模型往往无法在test集合上表现良好，就像射击时从一个靶心附近打出一支箭，但是实际靶心的位置偏离之前的靶心。

在样本数量不多（小于一万）的情况下，通常将Train/dev/test集合的比例设为60%/20%/20%。在没有dev集合的情况下，可以将Train/test集合的比例设为70%/30%。而在样本数量很大（百万级别）的情况下，通常将比例设为98%/1%/1%或者99%/1%。


有时候需要根据实际情况动态调整算法模型的评价标准。

以猫类识别为例，初始的评价标准是错误率，算法A的错误率为3%，算法B的错误率为5%。
显然，算法A更好一些。然而，在实际使用中，发现算法A会误识别一些色情图片，而算法B则没有这个问题。从用户的角度来看，他们可能更倾向于选择算法B，尽管它的错误率更高。

在这种情况下，我们需要改变之前的评价标准，考虑到新情况进行调整。例如，增加色情图片的权重，增加其代价。

改变前的损失函数（Cost Function）：
$$J=\frac1m\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)})$$
改变评价标准后的损失函数（Cost Function）：
$$J=\frac1{w^{(i)}}\sum_{i=1}^mw^{(i)}L(\hat{y}^{(i)},y^{(i)})$$
$$\left.w^{(i)}=\left\{\begin{array}{ll}1,&x^{(i)}\textit{is non}-porn\\10,&x^{(i)}\textit{is porn}\end{array}\right.\right.$$
总结来说，机器学习可以分为两个过程：

1. 定义评价分类器的指标；
2. 如何在这个指标上取得好的成绩。

也就是说，第一步是找到靶心，第二步是通过训练将箭射中靶心。在训练的过程中，可能需要根据实际情况改变算法模型的评价标准，进行动态调整。另外，当dev/test集合与实际使用的样本分布不一致时，也需要动态调整评价标准。



# 6 人类水平表现

在深度学习中，我们经常将机器学习模型的表现与人类水平表现进行比较。
![](assets/1机器学习策略(1)_1.png)
图中，横坐标表示训练时间，纵坐标表示准确性。机器学习模型在训练过程中会逐渐接近甚至超过人类的表现水平。
然而，一旦超过了人类水平表现，进一步提升模型准确性的速度就会变慢，直到接近理想的最优准确性，，我们称之为贝叶斯最优误差（bayes optimal error）。理论上来说，任何模型都不可能超越这个最优准确性，它代表着最佳的表现水平。

人类在某些领域有很出色的表现，比如图像识别和语音识别等。因此，让机器学习模型不断接近人类水平表现是非常重要的，也需要付出很多努力：
- 从人类那里获取有标签的数据
- 从错误分析中获取见解：为什么一个人能够得到正确答案
- 更好地分析偏差/方差

在实际应用中，我们需要关注训练误差、验证误差和人类水平误差之间的相对值。

例如，对于猫类识别的问题，如果人类水平误差为1%，训练误差为8%，验证误差为10%。
![](assets/1机器学习策略(1)_2.png)
由于训练误差与人类水平误差相差7%，验证误差与训练误差相差2%，因此目标是尽量减小训练误差，也就是减小偏差。

如果图像非常模糊，人眼看不清楚，人类水平误差上升到了7.5%。
![](assets/1机器学习策略(1)_3.png)
在这种情况下，由于训练误差与人类水平误差只相差0.5%，验证误差与训练误差相差2%，因此目标是尽量减小验证误差，也就是减小方差。这是相对而言的。

对于物体识别这样的计算机视觉问题，人类水平误差非常低，接近于贝叶斯最佳误差。

因此，上面的例子中的1%和7.5%都可以近似看作是对应贝叶斯最佳误差的表示。

在实际应用中，我们通常使用人类水平误差来代表贝叶斯最佳误差。

一般来说，训练误差与人类水平误差之间的差值被称为偏差，也称为可避免偏差；验证误差与训练误差之间的差值被称为方差。

通过比较偏差和方差的相对大小，我们可以判断算法模型是否出现欠拟合或过拟合的情况。

我们之前提到过，人类水平表现能够代表贝叶斯最佳误差。但是，人类水平表现如何被定义？

以医学图像识别为例，不同人群的错误率会有所不同：

- 典型人类：误差率为3%
- 典型医生：误差率为1%
- 经验丰富的医生：误差率为0.7%
- 由经验丰富的医生组成的团队：误差率为0.5%

不同人群的错误率不同。通常情况下，我们将表现最好的那一组即由经验丰富的医生组成的团队作为人类水平表现。

那么，在这个例子中，人类水平误差为0.5%。

然而，在实际应用中，不同的人可能选择不同的人类水平标准，这会带来一些影响。

如果某个模型的训练误差为0.7%，验证误差为0.8%。
![](assets/1机器学习策略(1)_4.png)
如果选择由经验丰富的医生组成的团队作为人类水平表现，即人类水平误差为0.5%，那么偏差比方差更突出。

如果选择经验丰富的医生，即人类水平误差为0.7%，那么方差更突出。

也就是说，选择不同的人类水平误差，在某些情况下可能会影响偏差和方差的相对变化。

当然，这种情况通常只会在模型表现非常好，接近贝叶斯最佳误差的时候出现。

对于自然感知问题，例如视觉、听觉等问题，机器学习的表现不如人类。但是在很多其他方面，例如在线广告、产品推荐、物流（预测运输时间）和贷款批准等方面，机器学习模型的表现已经超过了人类。

实际上，使机器学习模型超过人类水平表现是相当困难的。

然而，只要提供足够多的样本数据，训练复杂的神经网络，模型的预测准确性就会大大提高，很有可能接近或甚至超过人类水平。

需要注意的是，当算法模型的表现超过人类水平时，很难通过人的直觉来解决如何进一步提升模型性能的问题。

# 7 提高模型性能

提高机器学习模型的性能主要涉及两个问题：可避免的偏差（avoidable bias）和方差（variance）。可避免的偏差指的是训练误差与人类水平误差之间的差距，而方差指的是验证误差与训练误差之间的差距。

解决可避免的偏差的常用方法包括：
- 训练更大的模型
- 进行更长时间/更好的优化算法（如动量、RMSprop、Adam）
- 搜索更好的神经网络架构和超参数

解决方差的常用方法包括：
- 增加数据量
- 正则化（如L2正则化、dropout和数据增强）
- 搜索更好的神经网络架构和超参数

通过采用这些方法，我们可以逐步改善模型性能，并使其接近最优水平。